{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime\n",
    "\n",
    "from pyspark.sql import Row\n",
    "\n",
    "month_map = {'Jan': 1, 'Feb': 2, 'Mar':3, 'Apr':4, 'May':5, 'Jun':6, 'Jul':7,\n",
    "    'Aug':8,  'Sep': 9, 'Oct':10, 'Nov': 11, 'Dec': 12}\n",
    "\n",
    "def parse_apache_time(s):\n",
    "    return datetime.datetime(int(s[7:11]),\n",
    "                             month_map[s[3:6]],\n",
    "                             int(s[0:2]),\n",
    "                             int(s[12:14]),\n",
    "                             int(s[15:17]),\n",
    "                             int(s[18:20]))\n",
    "\n",
    "\n",
    "def parseApacheLogLine(logline):\n",
    "    match = re.search(APACHE_ACCESS_LOG_PATTERN, logline)\n",
    "    if match is None:\n",
    "        return (logline, 0)\n",
    "    size_field = match.group(9)\n",
    "    if size_field == '-':\n",
    "        size = long(0)\n",
    "    else:\n",
    "        size = long(match.group(9))\n",
    "    return (Row(\n",
    "        host          = match.group(1),\n",
    "        client_identd = match.group(2),\n",
    "        user_id       = match.group(3),\n",
    "        date_time     = parse_apache_time(match.group(4)),\n",
    "        method        = match.group(5),\n",
    "        endpoint      = match.group(6),\n",
    "        protocol      = match.group(7),\n",
    "        response_code = int(match.group(8)),\n",
    "        content_size  = size\n",
    "    ), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A regular expression pattern to extract fields from the log line\n",
    "APACHE_ACCESS_LOG_PATTERN = '^(\\S+) (\\S+) (\\S+) \\[([\\w:/]+\\s[+\\-]\\d{4})\\] \"(\\S+) (\\S+)\\s*(\\S*)\" (\\d{3}) (\\S+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from test_helper import Test\n",
    "\n",
    "baseDir = os.path.join('data')\n",
    "inputPath = os.path.join('cs100', 'lab2', 'apache.access.log.PROJECT')\n",
    "logFile = os.path.join(baseDir, inputPath)\n",
    "\n",
    "def parseLogs():\n",
    "    \"\"\" Read and parse log file \"\"\"\n",
    "    parsed_logs = (sc\n",
    "                   .textFile(logFile)\n",
    "                   .map(parseApacheLogLine)\n",
    "                   .cache())\n",
    "\n",
    "    access_logs = (parsed_logs\n",
    "                   .filter(lambda s: s[1] == 1)\n",
    "                   .map(lambda s: s[0])\n",
    "                   .cache())\n",
    "\n",
    "    failed_logs = (parsed_logs\n",
    "                   .filter(lambda s: s[1] == 0)\n",
    "                   .map(lambda s: s[0]))\n",
    "    failed_logs_count = failed_logs.count()\n",
    "    if failed_logs_count > 0:\n",
    "        print 'Number of invalid logline: %d' % failed_logs.count()\n",
    "        for line in failed_logs.take(20):\n",
    "            print 'Invalid logline: %s' % line\n",
    "\n",
    "    print 'Read %d lines, successfully parsed %d lines, failed to parse %d lines' % (parsed_logs.count(), access_logs.count(), failed_logs.count())\n",
    "    return parsed_logs, access_logs, failed_logs\n",
    "\n",
    "\n",
    "# parsed_logs, access_logs, failed_logs = parseLogs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "APACHE_ACCESS_LOG_PATTERN = '^(\\S+) (\\S+) (\\S+) \\[([\\w:/]+\\s[+\\-]\\d{4})\\] \"(\\S+) (\\S+)\\s*(\\S*)\\s*\" (\\d{3}) (\\S+)'\n",
    "\n",
    "#parsed_logs, access_logs, failed_logs = parseLogs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Test.assertEquals(failed_logs.count(), 0, 'incorrect failed_logs.count()')\n",
    "Test.assertEquals(parsed_logs.count(), 1043177 , 'incorrect parsed_logs.count()')\n",
    "Test.assertEquals(access_logs.count(), parsed_logs.count(), 'incorrect access_logs.count()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_sizes = access_logs.map(lambda log: log.content_size).cache()\n",
    "print 'Content Size Avg: %i, Min: %i, Max: %s' % (\n",
    "    content_sizes.reduce(lambda a, b : a + b) / content_sizes.count(),\n",
    "    content_sizes.min(),\n",
    "    content_sizes.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "responseCodeToCount = (access_logs\n",
    "                       .map(lambda log: (log.response_code, 1))\n",
    "                       .reduceByKey(lambda a, b : a + b)\n",
    "                       .cache())\n",
    "responseCodeToCountList = responseCodeToCount.take(100)\n",
    "print 'Found %d response codes' % len(responseCodeToCountList)\n",
    "print 'Response Code Counts: %s' % responseCodeToCountList\n",
    "assert len(responseCodeToCountList) == 7\n",
    "assert sorted(responseCodeToCountList) == [(200, 940847), (302, 16244), (304, 79824), (403, 58), (404, 6185), (500, 2), (501, 17)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = responseCodeToCount.map(lambda (x, y): x).collect()\n",
    "print labels\n",
    "count = access_logs.count()\n",
    "fracs = responseCodeToCount.map(lambda (x, y): (float(y) / count)).collect()\n",
    "print fracs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def pie_pct_format(value):\n",
    "    return '' if value < 7 else '%.0f%%' % value\n",
    "\n",
    "fig = plt.figure(figsize=(4.5, 4.5), facecolor='white', edgecolor='white')\n",
    "colors = ['yellowgreen', 'lightskyblue', 'gold', 'purple', 'lightcoral', 'yellow', 'black']\n",
    "explode = (0.05, 0.05, 0.1, 0, 0, 0, 0)\n",
    "patches, texts, autotexts = plt.pie(fracs, labels=labels, colors=colors,\n",
    "                                    explode=explode, autopct=pie_pct_format,\n",
    "                                    shadow=False,  startangle=125)\n",
    "for text, autotext in zip(texts, autotexts):\n",
    "    if autotext.get_text() == '':\n",
    "        text.set_text('') \n",
    "plt.legend(labels, loc=(0.80, -0.1), shadow=True)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hostCountPairTuple = access_logs.map(lambda log: (log.host, 1))\n",
    "\n",
    "hostSum = hostCountPairTuple.reduceByKey(lambda a, b : a + b)\n",
    "\n",
    "hostMoreThan10 = hostSum.filter(lambda s: s[1] > 10)\n",
    "\n",
    "hostsPick20 = (hostMoreThan10\n",
    "               .map(lambda s: s[0])\n",
    "               .take(20))\n",
    "\n",
    "print 'Any 20 hosts that have accessed more then 10 times: %s' % hostsPick20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "endpoints = (access_logs\n",
    "             .map(lambda log: (log.endpoint, 1))\n",
    "             .reduceByKey(lambda a, b : a + b)\n",
    "             .cache())\n",
    "ends = endpoints.map(lambda (x, y): x).collect()\n",
    "counts = endpoints.map(lambda (x, y): y).collect()\n",
    "\n",
    "fig = plt.figure(figsize=(8,4.2), facecolor='white', edgecolor='white')\n",
    "plt.axis([0, len(ends), 0, max(counts)])\n",
    "plt.grid(b=True, which='major', axis='y')\n",
    "plt.xlabel('Endpoints')\n",
    "plt.ylabel('Number of Hits')\n",
    "plt.plot(counts)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "endpointCounts = (access_logs\n",
    "                  .map(lambda log: (log.endpoint, 1))\n",
    "                  .reduceByKey(lambda a, b : a + b))\n",
    "\n",
    "topEndpoints = endpointCounts.takeOrdered(10, lambda s: -1 * s[1])\n",
    "\n",
    "print 'Top Ten Endpoints: %s' % topEndpoints\n",
    "assert topEndpoints == [(u'/images/NASA-logosmall.gif', 59737), (u'/images/KSC-logosmall.gif', 50452), (u'/images/MOSAIC-logosmall.gif', 43890), (u'/images/USA-logosmall.gif', 43664), (u'/images/WORLD-logosmall.gif', 43277), (u'/images/ksclogo-medium.gif', 41336), (u'/ksc.html', 28582), (u'/history/apollo/images/apollo-logo1.gif', 26778), (u'/images/launch-logo.gif', 24755), (u'/', 20292)], 'incorrect Top Ten Endpoints'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "not200 = access_logs.filter(lambda log: log.response_code != 200)\n",
    "\n",
    "endpointCountPairTuple = not200.map(lambda log: (log.endpoint, 1))\n",
    "\n",
    "endpointSum = endpointCountPairTuple.reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "topTenErrURLs = endpointSum.takeOrdered(10, lambda s: -1 * s[1])\n",
    "print 'Top Ten failed URLs: %s' % topTenErrURLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hosts = access_logs.map(lambda log: (log.host, 1))\n",
    "\n",
    "uniqueHosts = hosts.groupByKey()\n",
    "\n",
    "uniqueHostCount = uniqueHosts.count()\n",
    "print 'Unique hosts: %d' % uniqueHostCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dayToHostPairTuple = access_logs.map(lambda log: (log.date_time.day, log.host))\n",
    "\n",
    "dayGroupedHosts = dayToHostPairTuple.groupByKey()\n",
    "\n",
    "dayHostCount = dayGroupedHosts.map(lambda s: (s[0], len(list(set(s[1])))))\n",
    "\n",
    "dailyHosts = (dayHostCount\n",
    "              .sortByKey().cache())\n",
    "dailyHostsList = dailyHosts.take(30)\n",
    "print 'Unique hosts per day: %s' % dailyHostsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "daysWithHosts = dailyHosts.map(lambda s: s[0]).collect()\n",
    "hosts = dailyHosts.map(lambda s: s[1]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4.5), facecolor='white', edgecolor='white')\n",
    "plt.axis([min(daysWithHosts), max(daysWithHosts), 0, max(hosts)+500])\n",
    "plt.grid(b=True, which='major', axis='y')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Hosts')\n",
    "plt.plot(daysWithHosts, hosts)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dayAndHostTuple = access_logs.map(lambda log: (log.date_time.day, log.host))\n",
    "\n",
    "groupedByDay = dayAndHostTuple.groupByKey()\n",
    "\n",
    "sortedByDay = groupedByDay.sortByKey()\n",
    "\n",
    "avgDailyReqPerHost = (sortedByDay\n",
    "                      .map(lambda s: (s[0], len(s[1]) / len(list(set(s[1])))))).cache()\n",
    "avgDailyReqPerHostList = avgDailyReqPerHost.take(30)\n",
    "print 'Average number of daily requests per Hosts is %s' % avgDailyReqPerHostList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "daysWithAvg = avgDailyReqPerHost.map(lambda s: s[0]).collect()\n",
    "avgs = avgDailyReqPerHost.map(lambda s: s[1]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4.2), facecolor='white', edgecolor='white')\n",
    "plt.axis([0, max(daysWithAvg), 0, max(avgs)+2])\n",
    "plt.grid(b=True, which='major', axis='y')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Average')\n",
    "plt.plot(daysWithAvg, avgs)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "badRecords = (access_logs\n",
    "              .filter(lambda log: log.response_code == 404)).cache()\n",
    "print 'Found %d 404 URLs' % badRecords.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "badEndpoints = badRecords.map(lambda log: log.endpoint)\n",
    "\n",
    "badUniqueEndpoints = badEndpoints.distinct()\n",
    "\n",
    "badUniqueEndpointsPick40 = badUniqueEndpoints.take(40)\n",
    "print '404 URLS: %s' % badUniqueEndpointsPick40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "badEndpointsCountPairTuple = badRecords.map(lambda log: (log.endpoint, 1))\n",
    "\n",
    "badEndpointsSum = badEndpointsCountPairTuple.reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "badEndpointsTop20 = badEndpointsSum.takeOrdered(20, lambda s: -1 * s[1])\n",
    "print 'Top Twenty 404 URLs: %s' % badEndpointsTop20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errHostsCountPairTuple = badRecords.map(lambda log: (log.host, 1))\n",
    "\n",
    "errHostsSum = errHostsCountPairTuple.reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "errHostsTop25 = errHostsSum.takeOrdered(25, lambda s: -1 * s[1])\n",
    "print 'Top 25 hosts that generated errors: %s' % errHostsTop25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errDateCountPairTuple = badRecords.map(lambda log: (log.date_time.day, 1))\n",
    "\n",
    "errDateSum = errDateCountPairTuple.reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "errDateSorted = (errDateSum\n",
    "                 .sortByKey()).cache()\n",
    "\n",
    "errByDate = errDateSorted.collect()\n",
    "print '404 Errors by day: %s' % errByDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "daysWithErrors404 = errDateSorted.map(lambda s: s[0]).collect()\n",
    "errors404ByDay = errDateSorted.map(lambda s: s[1]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4.2), facecolor='white', edgecolor='white')\n",
    "plt.axis([0, max(daysWithErrors404), 0, max(errors404ByDay)])\n",
    "plt.grid(b=True, which='major', axis='y')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('404 Errors')\n",
    "plt.plot(daysWithErrors404, errors404ByDay)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topErrDate = errDateSorted.takeOrdered(5, lambda s: -1 * s[1])\n",
    "print 'Top Five dates for 404 requests: %s' % topErrDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hourCountPairTuple = badRecords.map(lambda log: (log.date_time.hour, 1))\n",
    "\n",
    "hourRecordsSum = hourCountPairTuple.reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "hourRecordsSorted = (hourRecordsSum\n",
    "                     .sortByKey()).cache()\n",
    "\n",
    "errHourList = hourRecordsSorted.collect()\n",
    "print 'Top hours for 404 requests: %s' % errHourList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "hoursWithErrors404 = hourRecordsSorted.map(lambda s: s[0]).collect()\n",
    "errors404ByHours = hourRecordsSorted.map(lambda s: s[1]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,4.2), facecolor='white', edgecolor='white')\n",
    "plt.axis([0, max(hoursWithErrors404), 0, max(errors404ByHours)])\n",
    "plt.grid(b=True, which='major', axis='y')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('404 Errors')\n",
    "plt.plot(hoursWithErrors404, errors404ByHours)\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
